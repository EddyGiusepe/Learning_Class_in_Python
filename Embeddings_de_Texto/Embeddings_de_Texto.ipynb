{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd70a007",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"><font color=\"red\">Embeddings de Texto</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692e5993",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e532542",
   "metadata": {},
   "source": [
    "Link de estudo:\n",
    "\n",
    "* [Medium: Embeddings](https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63a1da",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Os `Embeddings` também são vetores números, podem capturar o significado. Assim, você pode utilizá-los para fazer uma busca `semântica` e até trabalhar com documentos em diferentes idiomas.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602676d",
   "metadata": {},
   "source": [
    "# <font color=\"pink\">Evolução dos Embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a8f27",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">Bag of Words</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61bdee",
   "metadata": {},
   "source": [
    "Lembrando `stemização` (stemming) com NLTK Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17314d74-f0f5-4060-ade2-0c37e25dce37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/eddygiusepe/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/eddygiusepe/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Temos',\n",
       " 'sorte',\n",
       " 'de',\n",
       " 'viver',\n",
       " 'em',\n",
       " 'uma',\n",
       " 'época',\n",
       " 'em',\n",
       " 'que',\n",
       " 'ainda',\n",
       " 'estamos',\n",
       " 'fazendo',\n",
       " 'descobertas']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Baixar o recursos necessários para o processamento em português:\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Stemmer para português:\n",
    "stemmer = SnowballStemmer(language='portuguese')\n",
    "\n",
    "\n",
    "text = 'Temos sorte de viver em uma época em que ainda estamos fazendo descobertas'\n",
    "\n",
    "# tokenization - splitting text into words:\n",
    "words = word_tokenize(text)\n",
    "\n",
    "words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6708cb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tem',\n",
       " 'sort',\n",
       " 'de',\n",
       " 'viv',\n",
       " 'em',\n",
       " 'uma',\n",
       " 'époc',\n",
       " 'em',\n",
       " 'que',\n",
       " 'aind',\n",
       " 'estam',\n",
       " 'faz',\n",
       " 'descobert']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words = list(map(lambda x: stemmer.stem(x), words))\n",
    "\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb2427",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Agora, temos uma lista das formas básicas de todas as nossas palavras. O próximo passo é calcular suas frequências para criar um vetor.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4afd3c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'em': 2,\n",
       "         'tem': 1,\n",
       "         'sort': 1,\n",
       "         'de': 1,\n",
       "         'viv': 1,\n",
       "         'uma': 1,\n",
       "         'époc': 1,\n",
       "         'que': 1,\n",
       "         'aind': 1,\n",
       "         'estam': 1,\n",
       "         'faz': 1,\n",
       "         'descobert': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "bag_of_words = collections.Counter(stemmed_words)\n",
    "\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8f7b1",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Esta abordagem é `bastante básica` e não leva em consideração o significado `semântico das palavras`, portanto as frases `“A menina está estudando ciência de dados”` e `“A jovem está aprendendo IA e ML”` não estarão próximas uma da outra.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7e35b",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">TF-IDF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd06765",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Uma versão ligeiramente melhorada da abordagem `Bag of the Words` é `TF-IDF` (Term Frequency — Inverse Document Frequency).</font>\n",
    "\n",
    "Essa estratégia deu resultados um pouco melhores, mas mesmo assim não conseguiu significado semântico. `Olhando para isso, os cientistas começaram a pensar na representação vetorial densa.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce888330",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">Word2Vec</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebeba9e",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Uma das abordagens mais famosas para `representação densa` é o `word2vec`, proposto pelo `Google em 2013` no artigo `“Efficient Estimation of Word Representations in Vector Space”` de Mikolov et al.</font>\n",
    "\n",
    "O `word2vec` era capaz de trabalhar `apenas com palavras`, mas gostaríamos de codificar frases inteiras. Então, vamos passar para o próximo passo evolutivo com `Transformers`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0e6550",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">Transformers e Sentence Embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4280261",
   "metadata": {},
   "source": [
    "Um dos primeiros modelos populares foi o `BERT` (Bidirectional Encoder Representations from Transformers) do Google AI.\n",
    "\n",
    "Internamente, o `BERT` ainda opera em um nível de token semelhante ao `word2vec`, mas ainda queremos obter incorporações de frases. Portanto, a abordagem ingênua poderia ser obter uma média dos vetores de todos os tokens. Infelizmente, essa abordagem não apresenta bom desempenho.\n",
    "\n",
    "Esse problema foi resolvido em `2019`, quando o `Sentence-BERT` foi lançado. Superou todas as abordagens anteriores para tarefas de `similaridade textual semântica` e permitiu o cálculo de `Embeddings de frases`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85118aad",
   "metadata": {},
   "source": [
    "# <font color=\"pink\">Calculando Embeddings</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22017e",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Aqui usaremos `Embeddings OpenAI`. Tentaremos um novo modelo `text-embedding-3-small` que foi [lançado recentemente](https://openai.com/blog/new-embedding-models-and-api-updates). O novo modelo apresenta melhor desempenho em comparação com `text-embedding-ada-002`:\n",
    "\n",
    "* A pontuação média em um `benchmark` de recuperação multilíngue amplamente utilizado ([MIRACL](https://github.com/project-miracl/miracl)) aumentou de `31,4%` para `44,0%`.\n",
    "\n",
    "\n",
    "* O desempenho médio num benchmark frequentemente utilizado para tarefas de inglês (MTEB) também melhorou, passando de `61,0%` para `62,3%`.\n",
    "\n",
    "`OpenAI` também lançou um novo modelo maior `text-embedding-3-large`. Agora, é o modelo de `Embeddings` com melhor desempenho.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fbe2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitua sua chave de API OpenAI:\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24a0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model)\\\n",
    "       .data[0].embedding\n",
    "\n",
    "\n",
    "emb_frase = get_embedding(\"Temos sorte de viver numa época em que ainda fazemos descobertas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3c3c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emb_frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1b2d5",
   "metadata": {},
   "source": [
    "## <font color=\"gree\">Distância entre vetores</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7adb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vetores:\n",
    "vector1 = [ 1 , 4 ] \n",
    "vector2 = [ 2 , 2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47320c",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Distância euclidiana (L2)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b4f832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Euclidiana_forma_1 = sum(list(map(lambda x, y: (x - y) ** 2, vector1, vector2))) ** 0.5\n",
    "# 2.2361\n",
    "\n",
    "Euclidiana_forma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4054752e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidiana_forma_2 = np.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 2)\n",
    "\n",
    "round(Euclidiana_forma_2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f0d009",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Distância de Manhattan (L1)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a27491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manhattan_forma_1 = sum(list(map(lambda x, y: abs(x - y), vector1, vector2)))\n",
    "# 3\n",
    "\n",
    "Manhattan_forma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f2be6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Manhattan_forma_2 = np.linalg.norm((np.array(vector1) - np.array(vector2)), ord = 1)\n",
    "\n",
    "round(Manhattan_forma_2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fd700",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Produto escalar (`Dot product`)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad111e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DotProduct_forma1 = sum(list(map(lambda x, y: x*y, vector1, vector2)))\n",
    "\n",
    "DotProduct_forma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df36f8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DotProduct_forma2 = np.dot(vector1, vector2)\n",
    "\n",
    "round(DotProduct_forma2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970248f8",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Cosine similarity</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c727a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8574929257125441"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product = sum(list(map(lambda x, y: x*y, vector1, vector2)))\n",
    "norm_vector1 = sum(list(map(lambda x: x ** 2, vector1))) ** 0.5\n",
    "norm_vector2 = sum(list(map(lambda x: x ** 2, vector2))) ** 0.5\n",
    "\n",
    "Cosine_1 = dot_product/(norm_vector1*norm_vector2)\n",
    "\n",
    "Cosine_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45cec8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8575"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "Cosine_2 = cosine_similarity(np.array(vector1).reshape(1, -1), np.array(vector2).reshape(1, -1))[0][0]\n",
    "\n",
    "round(Cosine_2, 4)\n",
    "# 0.8575"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88120545",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Podemos até calcular o `ângulo exato` entre os nossos vetores em graus. Obtemos resultados em torno de `30 graus` e parece bastante razoável.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ac80532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.96"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "angulo_entre_vetores = math.degrees(math.acos(0.8575))\n",
    "\n",
    "round(angulo_entre_vetores, 2)\n",
    "# 30.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d08ab2",
   "metadata": {},
   "source": [
    "<font color=\"yellow\">Para tarefas de `NLP`, a prática recomendada geralmente é usar `similaridade de cosseno`. Algumas razões por trás disso:\n",
    "\n",
    "* A similaridade do cosseno está entre -1 e 1, enquanto L1 e L2 são ilimitados, por isso é mais fácil de interpretar.\n",
    "\n",
    "* Do ponto de vista prático, é mais eficaz calcular produtos escalares do que raízes quadradas para a distância euclidiana.</font>\n",
    "\n",
    "* <font color=\"red\">A similaridade de cossenos é menos afetada pela maldição da dimensionalidade.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664505f1",
   "metadata": {},
   "source": [
    "<font color=\"orange\">Os Embeddings OpenAI já são normalizados, portanto, o `produto escalar` e a `similaridade do cosseno` são iguais neste caso.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
